# MySQL
## 红黑树、B树、B+树
### 红黑树

红黑树是一种 **自平衡二叉搜索树**，通过颜色标记和旋转操作来保持树的平衡。

* 特点：高度平衡，最坏情况下操作复杂度为 **O(logN)**。
* 应用：常用于 **关联容器**（如 C++ 的 `std::map`、`std::set`）。
* 优势：插入、删除、查找操作效率稳定。

### B树

B树是一种 **多路平衡搜索树**，适合磁盘存储系统。

* 特点：每个节点可以包含多个键和子节点，降低树的高度。
* 优势：减少磁盘 I/O 次数，提高大规模数据存取效率。
* 应用：广泛应用于 **数据库和文件系统**。

### B+树

B+树是 **B树的变体**，在数据库索引中使用更普遍。

* 特点：

  * 所有数据都存储在 **叶子节点**。
  * 内部节点只存储键和指针。
  * 叶子节点之间通过指针构成 **双向链表**，支持高效的范围查询。
* 应用：常用于 **数据库索引**，尤其适合范围扫描和顺序访问。

我帮你重新整理成更清晰的 Markdown 格式，把表格和逻辑结构排版优化了一下：


## 文件索引和数据库索引为什么使用 B+ 树？

### B 树 vs B+ 树对比

| 特性     | B 树                 | B+ 树                |
| ------ | ------------------- | ------------------- |
| 数据存储位置 | 所有节点（包括内部节点）均可存储数据  | 仅叶子节点存储数据，内部节点仅存储键值 |
| 叶子节点链接 | 无顺序指针链接             | 叶子节点通过双向链表串联，支持区间访问 |
| 树高度    | 相对较高（节点存储数据，键密度低）   | 更低（内部节点仅存键，键密度高）    |
| 查询稳定性  | 数据分布在各层，查询时访问层次波动较大 | 所有查询均到达叶子节点，查询时间稳定  |

### MySQL 选择 B+ 树的原因

1. **更低的树高，减少磁盘 I/O**
   内部节点只存键值和指针，一个节点能容纳更多索引项 → 树高更低 → 查询更快。

2. **范围查询高效**
   叶子节点形成有序链表，区间查询只需链表遍历；B 树则需要多次回溯。

3. **全表扫描更优**
   所有数据在叶子节点，全表扫描只需遍历叶子链表即可。

4. **更适合磁盘预读**
   节点大小与磁盘页（4KB\~16KB）对齐，顺序访问性能更好。

5. **并发性能更优**
   支持 **Next-Key Lock**（范围锁），事务隔离更容易实现。

6. **插入与删除效率更高**

   * B+ 树有冗余节点（内部节点只存索引），删除/插入时更轻量。
   * B 树需要频繁调整内部节点，开销更大。


## 悲观锁和乐观锁

### 悲观锁（Pessimistic Lock）

* **原理**：先获取锁再修改，避免并发冲突。
* **实现**：`SELECT ... FOR UPDATE`

  ```sql
  BEGIN;
  SELECT * FROM orders WHERE id = 1 FOR UPDATE; -- 加行锁
  UPDATE orders SET amount = 100 WHERE id = 1;
  COMMIT;
  ```
* **优点**：保证强一致性。
* **缺点**：性能下降，可能死锁。
* **适用场景**：高冲突场景，如金融交易、库存扣减。

### 乐观锁（Optimistic Lock）

* **原理**：先操作，最后提交时检查版本。
* **实现**：版本号机制 / CAS

  ```sql
  UPDATE products
  SET stock = stock - 1, version = version + 1
  WHERE id = 100 AND version = 2;
  ```

  ```java
  AtomicInteger atomicInt = new AtomicInteger(5);
  atomicInt.compareAndSet(5, 10); // 当前值为 5 时更新为 10
  ```
* **优点**：无锁，高并发性能好。
* **缺点**：冲突时需重试，存在 ABA 问题。
* **适用场景**：读多写少，冲突概率低，如点赞计数、在线文档协作。


### 对比总结

| 维度   | 悲观锁                       | 乐观锁              |
| ---- | ------------------------- | ---------------- |
| 加锁时机 | 操作前加锁                     | 提交时校验            |
| 冲突处理 | 阻塞等待                      | 回滚或重试            |
| 性能   | 高冲突下稳定，低并发时性能差            | 低冲突下高效，高并发时重试成本高 |
| 典型应用 | 数据库行锁、Java `synchronized` | 版本号、CAS、分布式事务    |

## 数据库隔离级别

### 四种事务隔离级别
1. **读未提交（Read Uncommitted）**
   * 一个事务还没提交时，它的变更就能被其他事务看到。
2. **读已提交（Read Committed）**
   * 一个事务提交之后，它的变更才能被其他事务看到。
3. **可重复读（Repeatable Read）** —— MySQL InnoDB 的默认隔离级别
   * 一个事务执行过程中看到的数据，一直跟事务启动时看到的数据一致。
4. **串行化（Serializable）**
   * 会对记录加上读写锁。如果多个事务对同一条记录进行读写操作时发生冲突，后访问的事务必须等待前一个事务完成后才能继续。
### 各隔离级别可能出现的问题
* **读未提交**：可能发生 脏读、不可重复读、幻读
* **读已提交**：可能发生 不可重复读、幻读，但不会发生脏读
* **可重复读**：可能发生 幻读，但不会发生 脏读、不可重复读
* **串行化**：不会发生 脏读、不可重复读、幻读
### InnoDB 的「可重复读」处理方式

1. **快照读（普通 `SELECT`）**

   * 通过 **MVCC（多版本并发控制）** 避免幻读。
   * 事务中看到的数据始终与事务启动时一致，即使其他事务插入新数据，也不会被查询出来。

2. **当前读（`SELECT ... FOR UPDATE` 等）**

   * 通过 **Next-Key Lock（记录锁 + 间隙锁）** 避免幻读。
   * 如果其他事务在锁范围内插入数据，会被阻塞，无法插入。

### 幻读仍然可能出现的场景
1. **快照读下的幻读**
   * 事务 A 先查询，再更新事务 B 插入的记录。
   * 更新操作会“看到”事务 B 插入的数据，导致事务 A 前后查询结果条目数不一致。
2. **快照读与当前读混合的幻读**
   * 事务先进行快照读（看不到新插入的数据）。
   * 后续改用当前读查询时，却发现有新数据存在，导致两次查询结果不一致。


## 数据库的四种隔离级别是如何实现的？
### 1. 读未提交（Read Uncommitted）

* 实现方式：直接读取最新数据，不检查事务提交状态。
* 特点：可能出现 **脏读**。

### 2. 串行化（Serializable）

* 实现方式：通过 **加读写锁** 避免并行访问。
* 特点：最严格的隔离级别，但并发性能差。

### 3. 读已提交（Read Committed）

* 实现方式：通过 **Read View** 实现，每条语句执行前重新生成一次快照。
* 特点：可以避免脏读，但仍可能出现 **不可重复读**。


### 4. 可重复读（Repeatable Read，MySQL 默认）

* 实现方式：在事务启动时生成一个 **Read View**，整个事务期间都使用该快照。
* 特点：避免了脏读和不可重复读，但仍可能出现 **幻读**（通过间隙锁解决）。


## MySQL 中事务的启动时机

1. **`BEGIN / START TRANSACTION`**

   * 执行该命令后并不会马上启动事务。
   * 只有在执行第一条 `SELECT` 语句时，事务才真正启动。

2. **`START TRANSACTION WITH CONSISTENT SNAPSHOT`**

   * 执行后立即启动事务，并立刻生成 **一致性快照（Read View）**。

## Read View 的核心字段

| 字段                   | 含义                                         | 可见性判断                             |
| -------------------- | ------------------------------------------ | --------------------------------- |
| **m\_ids**           | 创建 Read View 时，当前「活跃事务」的事务 ID 列表（已开始但未提交）。 | 若 `trx_id ∈ m_ids` → **不可见**      |
| **min\_trx\_id**     | `m_ids` 中的最小值（活跃事务最小 ID）。                  | 若 `trx_id < min_trx_id` → **可见**  |
| **max\_trx\_id**     | 下一个将被分配的事务 ID（当前最大事务 ID + 1）。              | 若 `trx_id ≥ max_trx_id` → **不可见** |
| **creator\_trx\_id** | 创建该 Read View 的事务 ID。                      | 标识生成该快照的事务自身                      |

好的，我帮你把这份 **SQL 优化总结**重新排版成结构清晰、条理分明的 Markdown 版本，保持内容不变，只做格式优化：

---

## SQL 优化

### 1. 尽量避免使用子查询

低效写法：
```sql
SELECT * FROM t1 WHERE ID IN (SELECT ID FROM t2 WHERE NAME = 'chackca');
```
* 在 MySQL 5.5 中，执行计划是：先查外表再匹配内表 → 外表数据量大时，速度很慢。
* 在 MySQL 5.6 中，会自动优化为 `JOIN`：

  ```sql
  SELECT t1.* FROM t1 JOIN t2 ON t1.id = t2.id;
  ```
* 注意：优化仅对 `SELECT` 有效，对 `UPDATE/DELETE` 无效。
* 建议：避免子查询，改用 `INNER JOIN`，因为 `JOIN` 不需要创建临时表。

### 2. 用 IN 替换 OR

* 低效：

  ```sql
  SELECT * FROM t WHERE id = 10 OR id = 20 OR id = 30;
  ```
* 高效：

  ```sql
  SELECT * FROM t WHERE id IN (10,20,30);
  ```
* MySQL 会将 `IN` 中的常量存入有序数组，提高效率。
* 补充优化：

  * 连续值用 `BETWEEN` 替代 `IN`。
  * 可用 `JOIN` 替代过长的 `IN`。

### 3. 优化分页查询（LIMIT M,N）

问题：`LIMIT m, n` 随着 m 增大会越来越慢，因为 MySQL 会扫描 `offset+n` 行，再丢弃前 m 行。

优化方法：

```sql
-- 传统分页
SELECT ID, NAME FROM t LIMIT 866613,20;

-- 优化分页（上一页最大 ID 已知为 866612）
SELECT ID, NAME FROM t WHERE ID > 866612 LIMIT 20;
```

### 4. 禁止不必要的 ORDER BY 排序

* 若结果无需排序，避免 `ORDER BY`。
* 若排序字段无索引，也尽量少排序。
* `GROUP BY` 默认会排序，可禁止：

  ```sql
  SELECT goods_id, COUNT(*) 
  FROM t 
  GROUP BY goods_id 
  ORDER BY NULL;
  ```

### 5. 用 UNION ALL 替代 UNION

* `UNION` 会去重（涉及排序），消耗 CPU 和内存。
* 若确定结果集不会重复 → 使用 `UNION ALL` 更快。


### 6. 避免随机取记录

低效：

```sql
SELECT * FROM t1 ORDER BY RAND() LIMIT 4;
SELECT * FROM t1 WHERE id >= CEIL(RAND()*1000) LIMIT 4;
```

以上写法无法使用索引。


### 7. 多次 INSERT 改为批量 INSERT

低效：

```sql
INSERT INTO t(id, name) VALUES(1, 'aaa');
INSERT INTO t(id, name) VALUES(2, 'bbb');
INSERT INTO t(id, name) VALUES(3, 'ccc');
```

高效：

```sql
INSERT INTO t(id, name) VALUES(1, 'aaa'), (2, 'bbb'), (3, 'ccc');
```


### 8. 避免 SELECT \*

* `SELECT *` 会增加 CPU、IO、内存、网络消耗。
* 应写明具体字段名，增加使用 **覆盖索引** 的可能性。
* 覆盖索引可避免回表，减少 IO。


### 9. 区分 IN 和 EXISTS

```sql
-- IN
SELECT * FROM 表A WHERE id IN (SELECT id FROM 表B);

-- EXISTS
SELECT * FROM 表A 
WHERE EXISTS (SELECT * FROM 表B WHERE 表B.id = 表A.id);
```

* 驱动顺序不同：

  * `IN`：先执行子查询 → 适合 **外表大、内表小**。
  * `EXISTS`：外表为驱动表 → 适合 **外表小、内表大**。
* 建议：确定集合有限时用 `IN`，如 `IN (0,1,2)`。


### 10. 优化 GROUP BY

* 默认排序 → 若无排序需求，加 `ORDER BY NULL`。
* 尽量让 `GROUP BY` 使用索引，避免 `Using temporary` 和 `Using filesort`。
* 数据量小 → 内存临时表；数据量大 → 调整 `tmp_table_size` 或用 `SQL_BIG_RESULT`。
* 使用 `WHERE` 代替 `HAVING` 进行过滤。

示例：

```sql
-- 低效
SELECT JOB, AVG(SAL) FROM EMP GROUP BY JOB HAVING JOB = 'PRESIDENT' OR JOB = 'MANAGER';

-- 高效
SELECT JOB, AVG(SAL) FROM EMP WHERE JOB IN ('PRESIDENT','MANAGER') GROUP BY JOB;
```

### 11. 优先使用数字型字段

* 数字比较效率高于字符串比较。
* 查询与连接时，字符串逐字符对比更慢。

### 12. 优化 JOIN 语句

#### 驱动表 vs 被驱动表

1. **无 WHERE 条件**

   * `LEFT JOIN` → 左表为驱动表
   * `RIGHT JOIN` → 右表为驱动表
   * `INNER JOIN` → MySQL 自动选择小表驱动大表
   * `STRAIGHT_JOIN` → 强制左表为驱动表

2. **有 WHERE 条件**

   * 带条件的表通常为驱动表

#### Join 算法

1. **Index Nested-Loop Join (NLJ)**

   * 被驱动表有索引
   * 驱动表逐行取数据，利用索引查找被驱动表

2. **Block Nested-Loop Join (BNLJ)**

   * 被驱动表无索引
   * 驱动表数据存入 `join_buffer`，再与被驱动表逐行对比

3. **Simple Nested-Loop Join (SLJ)**

   * 驱动表逐行取数据，被驱动表做全表扫描
#### 实践优化

* 用小结果集驱动大结果集（小表驱动大表）。
* 优化内层循环性能，效果最明显。
* 在被驱动表的 `JOIN` 字段上建索引。
* 无法建索引时，适当调大 `join_buffer_size`。
* 优先用 `INNER JOIN`，避免不必要的 `LEFT JOIN`。
* 对右表 `JOIN` 字段建索引。
* 必要时冗余字段减少 JOIN 次数。
* 硬件优化：SSD 优于 HDD。

示例：

```sql
SELECT * FROM atable 
LEFT JOIN btable ON atable.aid = btable.bid;
-- 应在 btable.bid 上建索引
```


## 为什么要进行分库分表？一个库或一个表不行吗？

数据库在业务规模扩大、数据量快速增长时，单库单表容易成为性能瓶颈。分库与分表的主要目的在于**减小数据库负担、提高查询性能、缩短响应时间**。

### 分表的作用

* **降低单表压力**：减少单表的数据量，使查询效率更高。
* **缓解锁竞争**：数据分散后，表锁、行锁的冲突大幅减轻。
* **提高并发能力**：多表并行查询和写入，避免热点问题。

### 分表方式

1. **水平分表**（按行拆分数据）

   * **哈希取模**：根据字段（如 user\_id）的哈希值分片，例如 `user_id % 4`。
   * **范围分片**：按时间区间（如按月）、数值区间（如订单 ID）划分。
   * **一致性哈希**：减少扩容时的数据迁移，常用于避免取模分片带来的全量迁移。

   注：取模分表属于随机分布，时间维度分表属于连续分布。

2. **垂直分表**（按列拆分数据）

   * **分库**：按业务模块拆分，例如用户库、订单库、商品库，降低耦合度。
   * **分表**：将宽表中的字段按使用频率或属性拆分：

     * 不常用字段放入扩展表；
     * 大文本字段单独拆分；
     * 经常修改的字段和稳定字段分开存储。


### 库内分表的局限

* 虽然缓解了单表过大问题，但数据仍在同一物理机上，依旧存在 **CPU、内存、磁盘 I/O、网络带宽** 的竞争瓶颈。

### 分库分表带来的挑战

* **数据迁移与扩容**：需通过程序读写，将旧表数据重新分配到新分片。
* **分页与排序**：跨分表查询时，需要先在各分表中执行，再进行结果合并与排序。


## 数据库引擎 InnoDB 与 MyISAM 的区别

### InnoDB

* **事务型引擎**：MySQL 默认的事务型存储引擎，只有在需要其不支持的特性时才考虑其他引擎。
* **事务隔离**：实现了四个标准的隔离级别，默认是 **可重复读 (Repeatable Read)**。在此级别下，利用 **MVCC（多版本并发控制）+ 间隙锁（Next-Key Lock）** 防止幻读。
* **索引结构**：主索引为 **聚簇索引**，索引中保存数据，减少磁盘 I/O，提高查询性能。
* **优化机制**：

  * 可预测性读，优化磁盘读取；
  * 自适应哈希索引，加速查询；
  * 插入缓冲区，提高插入性能。
* **备份能力**：支持真正的 **在线热备份**，无需停止写入即可获得一致性视图。


### MyISAM

* **设计特点**：结构简单，数据存储紧凑。适合只读数据，或小表场景，容忍修复操作时可使用。
* **功能特性**：支持 **压缩表** 和 **空间数据索引**。
* **事务支持**：不支持事务。
* **锁机制**：

  * 不支持行级锁，只能 **表级锁**；
  * 读取时为整表加共享锁；
  * 写入时为整表加排它锁；
  * 但允许在表读取的同时执行 **并发插入**。

### 总结对比

* **事务**：InnoDB 支持事务，可使用 Commit / Rollback；MyISAM 不支持。
* **并发控制**：InnoDB 支持 **行级锁**；MyISAM 仅支持 **表级锁**。
* **外键**：InnoDB 支持外键；MyISAM 不支持。
* **备份**：InnoDB 支持在线热备份；MyISAM 不支持。
* **崩溃恢复**：MyISAM 崩溃后更易损坏，恢复更慢；InnoDB 恢复能力更强。
* **其它特性**：MyISAM 支持 **压缩表**、**空间数据索引**。


## 什么是 MVCC？

**MVCC（多版本并发控制, Multi-Version Concurrency Control）** 是数据库管理系统（DBMS）中的一种并发控制机制。
它的目标是：**提升数据库并发性能，同时保证事务隔离性和一致性**。
核心方法是 **维护数据的多个版本**，允许 **读操作不被写操作阻塞**，从而提升系统整体性能。


### MVCC 的核心思想

* **多版本数据**：为每行数据维护多个版本，每个版本带有时间戳或事务 ID，用于标识创建时间与可见性。
* **读写分离**：读操作读取事务开始时可见的数据版本；写操作则创建新版本，不影响正在进行的读操作。
* **无阻塞并发**：读操作无需等待写操作完成，实现高并发读写。


### MVCC 的工作原理

1. **事务开始**：每个事务会被分配一个唯一的事务 ID（或时间戳）。
2. **读数据**：根据事务 ID/时间戳选择可见的数据版本；只读到事务开始前提交的版本。
3. **写数据**：创建数据的新版本，并打上事务 ID/时间戳；旧版本仍然保留供其他事务使用。
4. **事务提交**：提交后，写入的新版本对其他事务可见；未提交的版本保持不可见。
5. **垃圾回收**：旧版本数据在无人需要时，通过垃圾回收清理释放空间。


### MVCC 的优点

* **高并发性**：读写可并发，避免传统锁带来的冲突。
* **无阻塞读取**：读写互不阻塞。
* **一致性视图**：事务读取到的数据始终保持一致。
* **支持回滚**：依赖旧版本数据，天然支持事务回滚。

### MVCC 的缺点

* **存储开销**：需维护多个版本，占用更多存储空间。
* **垃圾回收开销**：清理旧版本带来额外性能负担。
* **实现复杂**：需要精细的版本和可见性管理机制。


### MVCC 与隔离级别

* **读已提交 (Read Committed)**：事务只能读取已提交的数据。
* **可重复读 (Repeatable Read)**：事务启动后看到的数据不会改变。
* **串行化 (Serializable)**：最高隔离级别，通过严格版本控制实现。





好的，我帮你把这一段长内容优化成更清晰的排版和层次结构，保持原始信息完整不变：


## Undo Log、Redo Log、Binlog 及其区别

### Undo Log

**定义**：Undo Log 是 **InnoDB 存储引擎层**生成的日志，用于实现事务的 **原子性**。
在事务更新数据库之前，会先生成 Undo Log 来记录更新前的数据，并写入 Buffer Pool 中的 Undo 页。

**记录信息**：

* 操作类型（插入、删除、更新）
* 修改前的数据值
* 被修改的数据的位置
* 事务 ID
* 每次更新会生成 `roll_pointer`（指向旧记录，形成版本链）和 `trx_id`（标识事务）。

**作用**：

1. **事务回滚**：出现错误或执行 `ROLLBACK` 时，可用 Undo Log 恢复数据。
2. **实现 MVCC**：Undo Log 为每条记录保存多份历史数据，配合 Read View 实现快照读，事务根据版本链读取可见数据。

### Redo Log

**定义**：Redo Log 也是 **InnoDB 存储引擎层**生成的日志，用于保证事务的 **持久性**。
它记录了数据页的物理修改，如 “XXX 表空间中的 YYY 页 ZZZ 偏移量做了 AAA 更新”。

**特点与机制**：

* 采用 **WAL（Write-Ahead Logging）技术**：先写日志，再在合适的时间刷新数据到磁盘。
* 写入流程：

  1. 内存中修改数据（标记为脏页）；
  2. 将修改写入 **Redo Log Buffer**；
  3. 在特定时机（提交、定时、Buffer 半满等）持久化到磁盘。

**刷盘时机**：

* MySQL 正常关闭时
* Redo Log Buffer 超过一半容量
* InnoDB 后台线程每秒刷一次
* 事务提交时强制刷盘

**优点**：

* 保证事务持久性，崩溃后可恢复数据
* 顺序写，减少磁盘随机写开销


### Redo Log 与 Undo Log 的区别

* **Redo Log**：记录 **修改后的数据值**，用于 **崩溃恢复**，保证事务持久性。
* **Undo Log**：记录 **修改前的数据值**，用于 **事务回滚**，保证事务原子性。

事务崩溃时：

* **提交前崩溃** → 用 Undo Log 回滚
* **提交后崩溃** → 用 Redo Log 恢复


### Binlog

**定义**：Binlog 是 **MySQL Server 层**生成的日志，记录了数据库表结构变更和数据修改（不记录查询操作）。

**特点**：

* 记录所有更新操作，事务提交时统一写入 Binlog 文件
* 用于 **数据备份** 和 **主从复制**
* 每个线程都有 **Binlog Cache**，提交时写入 Binlog 文件并清空

**Binlog 刷盘机制**：

* **write**：写入文件系统 Page Cache（未落盘，速度快）
* **fsync**：持久化到磁盘（涉及 I/O，开销大）

**参数控制**：

* `sync_binlog = 0`：仅 write，不 fsync，由操作系统决定落盘时机
* `sync_binlog = 1`：每次提交都 write + fsync
* `sync_binlog = N (N>1)`：每 N 次事务提交后执行一次 fsync



### Redo Log 与 Binlog 的区别

* **适用对象**：

  * Binlog → Server 层，适用于所有存储引擎
  * Redo Log → InnoDB 引擎专用
* **文件格式**：

  * Redo Log：物理日志，记录页修改
  * Binlog：三种格式（Statement、Row、Mixed）
* **写入方式**：

  * Redo Log：循环写，空间固定
  * Binlog：追加写，文件写满则切换新文件
* **用途**：

  * Redo Log → 崩溃恢复
  * Binlog → 备份、主从复制


### 三者类比

* **Undo Log**：像铅笔，随时可擦，记录事务执行前的数据，用于回滚和 MVCC。
* **Redo Log**：像钢笔，记录修改后的内容，保证持久性并提高写入性能。
* **Binlog**：像复印件，完整记录所有变更，用于复制和恢复。


### 总结表

| 特性   | Undo Log   | Redo Log   | Binlog     |
| ---- | ---------- | ---------- | ---------- |
| 层级   | InnoDB 引擎层 | InnoDB 引擎层 | Server 层   |
| 内容   | 修改前的值      | 修改后的值      | SQL 或行数据变化 |
| 作用   | 回滚、MVCC    | 崩溃恢复       | 主从复制、备份    |
| 写入时机 | 事务开始前      | 事务执行中      | 事务提交时      |


好的，我帮你把这一大段内容进行排版优化，保持原始信息不变，只增强层次感和可读性：

---

## 主从复制是怎么实现？

MySQL 的主从复制依赖于 **binlog**，也就是记录 MySQL 上的所有变化并以二进制形式保存在磁盘上。复制的过程就是将 binlog 中的数据从主库传输到从库上。这个过程一般是 **异步的**，也就是说主库执行事务操作的线程不会等待复制线程完成。

### 主从复制的三个阶段

1. **写入 Binlog**：主库写 binlog 日志，提交事务，并更新本地存储数据。
2. **同步 Binlog**：把 binlog 复制到所有从库，每个从库写入 relay log（中继日志）。
3. **回放 Binlog**：从库回放 binlog，更新存储引擎中的数据。

### 详细过程

* 主库：收到客户端提交事务请求 → 写 binlog → 提交事务 → 更新数据 → 返回“操作成功”。
* 从库：

  * 创建 **I/O 线程**，连接主库 log dump 线程，接收 binlog，并写入 relay log；
  * 创建 **SQL 线程**，读取 relay log，回放 binlog，更新数据引擎，实现数据一致性。

**结果**：完成主从复制后，可以实现 **写主库、读从库**，从而避免写锁影响读请求。


## Update 语句的执行过程

以 `UPDATE t_user SET name = 'xiaolin' WHERE id = 1;` 为例：

1. **执行器获取数据**：

   * 如果数据页在 Buffer Pool 中，直接返回；
   * 否则从磁盘读入 Buffer Pool，再返回记录。

2. **判断是否需要更新**：

   * 如果新旧值相同，停止更新；
   * 否则将更新前后的记录交给 InnoDB 执行更新。

3. **生成 Undo Log**：

   * 开启事务，记录更新前的旧值到 Undo Log（用于回滚 & MVCC）；
   * 同时记录对应的 Redo Log。

4. **更新数据**：

   * 修改内存页（标记为脏页）；
   * 写入 Redo Log Buffer；
   * 脏页不会立即写磁盘，由后台线程异步刷新（WAL 技术）。

5. **记录 Binlog**：

   * 执行完成后，生成 binlog，写入 binlog cache。
   * 事务提交时，统一刷入 binlog 文件。

6. **事务提交**：进入 **两阶段提交**，保证 Redo Log 与 Binlog 一致性。


## 为什么 MySQL 主键查询比别的查询快？

1. **主键是聚簇索引**

   * 数据行实际存储在主键索引的叶子节点；
   * 主键查询：一次查找即可定位数据；
   * 非主键查询：需要先查二级索引，再回表查主键。

2. **B+ 树的高效性**

   * 主键索引有序，支持高效范围查询；
   * 树高较低（3\~4 层可支撑亿级数据），查询复杂度 O(logN)。

3. **避免回表**

   * 主键查询天然覆盖索引；
   * 非主键若查询字段已在索引叶子节点上（覆盖索引），也无需回表。

4. **唯一性和非空约束**

   * 主键值唯一 → 最多返回一行，提前结束扫描；
   * 非空约束 → 减少逻辑判断。

5. **InnoDB 优化机制**

   * Buffer Pool：缓存热数据，减少磁盘 I/O；
   * Read-Ahead：顺序范围查询可触发预加载。


## 执行一条 SQL 查询语句，期间发生了什么？

1. **连接器**：建立连接，校验用户身份。
2. **查询缓存**：命中则直接返回（MySQL 8.0 已移除）。
3. **解析 SQL**：词法 + 语法分析，生成语法树。
4. **执行 SQL**：

   * 预处理：检查表/字段是否存在，扩展 `*`。
   * 优化：选择成本最小的执行计划。
   * 执行：按计划读取存储引擎数据，返回结果。

## 二级索引的回表查询

* **主键索引 B+Tree**：叶子节点存放完整数据行。
* **二级索引 B+Tree**：叶子节点存放主键值。

查询过程：

1. 通过二级索引找到主键值；
2. 再通过主键索引回表，获取完整记录。

**覆盖索引**：如果查询字段在二级索引叶子节点中即可获得（如 `SELECT id FROM product WHERE product_no='0002';`），则无需回表。


好的，我帮你优化一下排版，让层次更清晰，信息更易读：

---

## 联合索引及范围查询

**定义**：多个字段组合成一个索引，例如 `(product_no, name)`。

**存储顺序**：先按 `product_no` 排序，再在相同 `product_no` 下按 `name` 排序。

### 最左匹配原则

* **可以匹配**：

  * `WHERE a = 1`
  * `WHERE a = 1 AND b = 2`
  * `WHERE a = 1 AND b = 2 AND c = 3`

* **不能匹配**：

  * `WHERE b = 2`
  * `WHERE c = 3`
  * `WHERE b = 2 AND c = 3`

**原因**：B+Tree 按顺序存储，只有最左字段有序；`b`、`c` 在全局无序，仅在局部有序，因此不满足最左匹配时无法利用索引。


### 范围查询的影响

在联合索引的查询条件中，如果遇到 **范围查询**（如 `>`、`<`），则会 **停止匹配**，也就是说：

* 范围查询字段可以用到索引；
* 但在范围查询字段之后的字段将无法继续使用索引。

**例外情况**：
以下范围查询不会中断匹配：

* `>=`、`<=`
* `BETWEEN`
* `LIKE 'abc%'`（前缀匹配）


### 索引下推（Index Condition Pushdown，ICP）

查询示例：

```sql
SELECT * 
FROM table 
WHERE a > 1 AND b = 2;
```

在联合索引 `(a, b)` 下：

* 按照最左匹配原则，只有 `a` 字段能利用索引；
* 那么 `b = 2` 的判断是在索引里做？还是回表后做？

**不同版本行为**：

* **MySQL 5.6 之前**：只能通过主键回表逐行取出，再判断 `b = 2`。
* **MySQL 5.6 引入 ICP**：可以在遍历联合索引时，先对索引中包含的字段（如 b）做过滤，减少回表次数。

**判断依据**：

* 在执行计划（`EXPLAIN`）中，如果 `Extra` 字段显示 **Using index condition**，说明启用了索引下推优化。


好的，我帮你把这一段内容优化排版，保持原始信息完整：


## 索引失效

### 1. 模糊匹配导致失效

* **左模糊 / 左右模糊匹配**：

  * `LIKE '%xx'`
  * `LIKE '%xx%'`
    这两种写法会导致索引失效。


### 2. 对索引列进行表达式计算、函数、隐式类型转换

**（1）表达式计算**

```sql
SELECT * FROM t_user WHERE id + 1 = 10;
```

* 错误原因：索引保存的是字段的原始值，而不是 `id+1` 计算后的值。
* MySQL 只能逐行计算后判断条件 → 全表扫描。

**正确写法**：

```sql
SELECT * FROM t_user WHERE id = 9;
```


**（2）函数操作**

```sql
-- name 为二级索引
SELECT * FROM t_user WHERE LENGTH(name) = 6;
```

* 错误原因：索引保存的是原始值，而不是 `LENGTH(name)` 的计算结果。
* 无法利用索引，导致全表扫描。


**（3）隐式类型转换**

```sql
-- phone 为 varchar 类型
SELECT * FROM t_user WHERE phone = 1300000001;   -- 索引失效
SELECT * FROM t_user WHERE phone = '1300000001'; -- 正确写法
```

* 如果索引字段是 **字符串类型**，而查询条件传入 **整型参数**，MySQL 会自动将索引列进行 `CAST` 类型转换 → 导致索引失效。

**但注意**：

```sql
EXPLAIN SELECT * FROM t_user WHERE id = '1';
```

* 如果索引字段是 **整型 (int)**，查询条件传入的是 **字符串**，不会导致索引失效，仍然会走索引。


### 3. 联合索引未遵循最左匹配原则

* 联合索引要按照 **最左优先** 的方式进行匹配，否则索引失效。



### 4. OR 条件导致索引失效

* 如果在 `WHERE` 子句中：

  * `OR` 前的条件列是索引列；
  * `OR` 后的条件列不是索引列；

  那么索引会失效，执行 **全表扫描**。

**原因**：`OR` 的逻辑是“满足其一即可”，若存在非索引列条件，整体就无法只依赖索引判断。


好的，我帮你优化排版，保持内容完整，结构更清晰：


## SQL 注入是什么？如何防止 SQL 注入？MyBatis 如何防止 SQL 注入？

### 一、SQL 注入是什么？

SQL 注入是一种常见的 Web 安全漏洞。攻击者通过在应用程序输入字段中插入恶意 SQL 代码，欺骗数据库服务器执行非预期的 SQL 命令。

**可能导致的后果**：

* 数据泄露（获取敏感信息）
* 数据篡改（修改或删除数据）
* 权限提升（获取管理员权限）
* 数据库服务器被控制

**示例场景**：

```sql
-- 原始 SQL
SELECT * FROM users WHERE username = '输入的用户名' AND password = '输入的密码';
```

攻击者输入：

* 用户名：`admin' --`
* 密码：任意值

实际执行 SQL：

```sql
SELECT * FROM users WHERE username = 'admin' -- 'AND password = '任意值';
```

其中 `--` 是 SQL 注释符，导致密码验证被忽略，直接以 admin 身份登录。


### 二、如何防止 SQL 注入？

1. **使用参数化查询**（最有效方法）

   * 数据库引擎区分代码和数据，确保用户输入始终作为数据处理。

   ```java
   // 错误方式（拼接 SQL）
   String sql = "SELECT * FROM users WHERE username = '" + username + "'";

   // 正确方式（参数化查询）
   PreparedStatement stmt = connection.prepareStatement(
       "SELECT * FROM users WHERE username = ?");
   stmt.setString(1, username);
   ```

2. **使用 ORM 框架**

   * 如 Hibernate、JPA 等，底层自动使用参数化查询。

3. **输入验证和过滤**

   * 白名单验证：只允许特定字符集。
   * 类型检查：确保数字输入确实是数字。
   * 长度限制：防止缓冲区溢出攻击。

4. **最小权限原则**

   * 数据库用户只授予必要权限，避免使用 root 或 sa 账户连接数据库。

5. **其他措施**

   * 使用 Web 应用防火墙（WAF）
   * 定期更新数据库和应用程序
   * 错误处理时避免暴露数据库细节


### 三、MyBatis 如何防止 SQL 注入？

* MyBatis 提供 **`#{} 占位符`** 方式，会自动进行预编译和参数绑定，从而避免 SQL 注入。
* 例如：

  ```xml
  <!-- 安全写法 -->
  <select id="findUserById" resultType="User">
      SELECT * FROM users WHERE id = #{id}
  </select>
  ```
* 注意不要使用 `${}` 拼接参数：

  ```xml
  <!-- 不安全写法，存在注入风险 -->
  <select id="findUserById" resultType="User">
      SELECT * FROM users WHERE id = ${id}
  </select>
  ```

  `${}` 是直接字符串拼接，可能导致注入风险；而 `#{}` 才是参数化查询。

